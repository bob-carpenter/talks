---
title: "Stan C++ Development:<br /> Adding a New Function"
author: "Bob Carpenter & Sean Talts"
date: "August 2018 (StanCon Helsinki)"
output:
  ioslides_presentation:
    logo: img/stan-logo.png
    css: styles.css
#   incremental: true
widescreen: yes
---

```{r setup, include = FALSE, warning = FALSE, cache = TRUE, echo = FALSE, comment = ""}
```

```{r echo = FALSE, include = FALSE}
library(knitr)
library(ggplot2)
```

<style>
.gdbar img {
  background-color: transparent;
  color: transparent;
  width: 150px !important;
  height: 150px !important;
  margin: 8px 8px;
}

.gdbar {
  background-color: transparent;
  color: transparent;
  width: 400px !important;
  height: 170px !important;
}

slides > slide:not(.nobackground):before {
  width: 0px;
  height: 0px;
  background-size: 0px 0px;
}

li {
  font-family: verdana, lucida sans unicode;
  font-size: 24px;
  line-height: 1.45em;
}
pre {
  font-family: lucida console, monaco, menlo;
  font-size: 19px;
  line-height: 1.5em;
  font-weight: 500;
}
tt {
  font-family: monaco; lucida console;
  font-size: 24px;
}
code {
  font-family: monaco; lucida console;
  font-size: 24px;
}
</style>

# Part I: Introduction

## Online documentation
* `stan-dev/stan`: [Developer process overview](https://github.com/stan-dev/stan/wiki/Developer-process-overview)
* `stan-dev/stan`: [Contributing new functions to Stan](https://github.com/stan-dev/stan/wiki/Contributing-New-Functions-to-Stan) <br /> <br />
* `stan-dev/math`: [Adding a new function with known gradients](https://github.com/stan-dev/math/wiki/Adding-a-new-function-with-known-gradients)
* `stan-dev/math`: [Developer doc](https://github.com/stan-dev/math/wiki/Developer-Doc)



## Best and worst decisions for Stan?
<blockquote>
* We were asked at a conference, <br /> <br />
"What are the **best and worst decisions** you made regarding the implementation of Stan?"

* We answered
    - *Worst decision*: using C++
    - *Best decision*: using C++


## Why C++?
* It's **very powerful**
* A whole *new language with C++11* and beyond
* Performant *matrix and math libs* (like Fortran, unlike all else)
* *Control of memory* for autodiff arena (collect once w/o destructors)
* *Template overloads* for autodiff of templated C++ code
* *Static evaluation* of branchpoints (traits metaprograms)
* *Unfolding* code (recursive metaprograms)
* *Elimination of intermediates* (expression templates)
* *Native in-memory communication* with Python and R
* *Binary builds* allow native code releases (e.g., RStanArm)
* *Optimizing compilers* are very good

## Why *not*&nbsp; C++?
* it's **not the easiest language** in the world
* the spec is incomplete by design so *compilers vary*, even by optimization level
* it's been a *moving target* from C++03 to C++20
* low-level memory access and pointers makes it *dangerous*
* *binary builds* and distribution are a pain to manage
* *compile time* is disastrous with templating & optimization
    - we're working to correct this
* lacks the *cool factor* to attract open source hobbyists
    
# Part II: Code 
    
## Top level Stan architecture
* Stan *transpiler* converts Stan program to C++ class for model
    - *standard* parser, abstract syntax tree, generator design
* C++ model class includes the Stan *math library*
* C++ model class compiled *mostly header-only*
    - along with algorithms and math library
    - this will change in near future with separate translation units
* Result is *executable* (CmdStan) or *dynamically linkable* object code (RStan, PyStan)

## Stan program is translated to a C++ class
* Creates a C++ model class with fixed *concept* (C++ interface)
* Model class is *constructed with data*
* Implements a *function of continuous unconstrained parameters*
* *Data* may be discrete and/or continuous
* *Generated quantities* may be discrete and/or continuous
    
## Stan C++ class (continued)
* Details of `log_prob` function
    - applies to vector of *unconstrained parameters* (for algorithms)
    - returns *log posterior* (up to additive constant)
    - usually *coded as joint log density* with posterior via Bayes's rule
    - or *log penalized likelihood* for maximum likelihood
        - turns off Jacobian correction
* *Constrain and unconstrain* parameters
    - from constrained to unconstrained for initialization
    - from unconstrained to constrained to evaluate model block
    - log Jacobian for change of variables in unconstrained to constrained
* Produces *transformed parameters* and *generated quantities*


## The Stan to C++ transpiler
* Also known informally as the compiler or translator
* Translates Stan program to *C++ class*
* Written in C++ (with *Boost Spirit Qi* parser)
* All *code* in `<stan>/src/stan/lang`
    - parallel to I/O, inference algorithms, service, and memory directories
    - top-level call in `<stan>/src/stan/lang/compiler.hpp`
* Transpiler consists of
    - *parser and semantic actions* (`lang/grammars`): translate Stan to AST
    - *abstract syntax tree* (AST) (`lang/ast`): C++ representation of code
    - *generator* (`lang/generator`): convert AST to C++ code
 

## Built-in Stan functions
* Defined using C++ in the math library
    - definitions may *use autodiff*
    - or may *define gradients analytically* for efficiency
* Exposed in the Stan language
    - all that is needed is *addition of signatures* to symbol table
    - needed because Stan is *strongly statically typed*


## C++ Model Compiled to Object Code
* Includes the math library (using `#include`)
    - Stan functions defined in math library
    - some functionality directly in `stan/src`, such as transforms
* Compiled largely *header-only* as a unit
    - includes Stan model class (translated from Stan to C++)
    - Stan inference algorithms (MCMC, variational inference, optimization)
    - Stan services (front-end to Stan used by interfaces RStan, PyStan, CmdStan)
        - other interfaces call CmdStan directly
* *Exclusions* from header-only
    - parallel libaries (threading, MPI, and GPU)
    - ordinary differential equation solvers (from Sundials lib)
    
## CmdStan, RStan, PyStan
* These are the three *primitive interfaces*
    - other interfaces (Julia, Stata, MATLAB, Mathematica) *call CmdStan*
    - ScalaStan is its own *embedded language* that transpiles to a Stan program
* We'll be concentrating on the command line interface, CmdStan
* The interfaces *implement callbacks* for
    - interrupts
    - data input
    - data and diagnostic output
    - runtime console messages


## Stan GitHub Repository Structure
* All repos for Stan are in the `stan-dev` *GitHub organization*
* *Git submodule* structure
    - `cmdstan` includes `stan` (path `stan`)
    - `stan` includes `math` (path `lib/stan_math`)
* Math library *directly includes* (path `lib`)
    - Boost (general C++, math, RNG, stats parser)
    - Eigen (matrix arithmtic and linear algebra)
    - Sundials (ordinary differential equation solvers)
* From CmdStan perspective
    - Stan is at `stan`
    - Math lib is at `stan/lib/stan_math`
    - Other libs at `stan/lib/stan_math/lib`

## A Stan Program
* `Matrix program(Matrix data) {...}`
    - Function from data to a sample of parameter draws typical given that data and model
* Compiled with a few algorithms that use the model density to find typical parameter draws
* Most of the complexity lies in the likelihood and is built using functions in the Math library


## Most of Stan's code is in the Math library
* Provides users with many functions to express complicated likelihoods
* Autodiff system gives the algorithms the gradients they need automatically for any Stan or Math library code
* Split first into `stan` and `test`
* Stan split into `math`
* Split by container type: `scal`, `arr`, `mat` (this is going away)
* Split by functionality: `err`, `fun`, `meta`, `prob`, ...
    - e.g., from CmdStan:
    - `stan/lib/stan_math/stan/math/rev/scal/fun/log1p.hpp`
    
## Tests and continuous integration
* We use [googletest](https://github.com/google/googletest), a C++ testing framework for unit tests
    - test files *end in* `_test.cpp`
    - *macros* like `TEST(SuiteName, TestName)` and `EXPECT_EQ(actual, expected)`
* Test *directory structure* parallel to `src` stucture
* *Run tests locally* with `runTests.py` helper script on a directory or test
* *Jenkins* continuous integration server
    - at http://d1m1s1b1.stat.columbia.edu:8080/
    - Specified in code, in a top-level file named `Jenkinsfile`
* [This wiki](https://github.com/stan-dev/stan/wiki/Supported-C---Compilers-and-Language-Features) describes the OSs and toolchains tested

    
# Part III: Process

## Developer process
0. For *larger changes only*: *Discourse discussion* and/or design review
1. *GitHub issue* describing the problem (i.e., functional specification)
2. Add a description of the *proposed technical solution* to the GitHub issue
3. Code the solution *on a branch*
4. Create a *GitHub pull request* with *BSD license details*
    - developers maintain copyright, but must BSD license contributions before approval
5. [Code review](https://github.com/stan-dev/math/wiki/Developer-Doc#code-review-guidelines)
    - if changes requirested, return to (3)
5. *Merge* only after approval

## Setting up GitHub
* Create an account
* (optional) [Set up SSH keys](https://help.github.com/articles/connecting-to-github-with-ssh/)
* *Fork the relevant repositories* from the `stan-dev` organization
* `git clone --recursive <cmdstan repo>`
    - the recursive bit takes care of submodules
* *Add your fork as a remote* on the repo you care about

## Clone CmdStan
```{r, out.width = "100%"}
knitr::include_graphics("img/clone cmdstan.png")
```

## Fork Math repo
```{r, out.width = "100%"}
knitr::include_graphics("img/fork.png")
```


## My fork 
![](img/my fork.png)

## Set up fork as remote in local clone of CmdStan
```
$ git remote -v
origin	git@github.com:stan-dev/math.git (fetch)
origin	git@github.com:stan-dev/math.git (push)

$ git remote add sean git@github.com:seantalts/math.git

$ git remote -v
origin	git@github.com:stan-dev/math.git (fetch)
origin	git@github.com:stan-dev/math.git (push)
sean	git@github.com:seantalts/math.git (fetch)
sean	git@github.com:seantalts/math.git (push)
```

## Creating a pull request (PR)
Fairly *standard open source flow*:

1. (optional) create a branch
1. write code, tests, and doc
1. run appropriate checks - cpplint, appropriate unit tests, (optional) `clang-format`
1. add files
1. commit with a [message about what you were trying to accomplish](https://chris.beams.io/posts/git-commit/) 
1. `git push origin <branchname>`
1. open pull request on appropriate `stan-dev` repo

## Creating a branch
```
$ git checkout -b descriptive-branch-name
Switched to a new branch 'descriptive-branch-name'
```

## Running the checks
1. `python runTests.py -j{num_cores} path/to/test.cpp /path/to/test/dir`
1. `make cpplint`
1. (optional) [Auto-formatting - git hook, editor plugin](https://github.com/stan-dev/stan/wiki/Coding-Style-and-Idioms#clang-format)

## A complicated example
```
$ cd <math clone>
$ find . -name operands_and_partials.hpp

./stan/math/fwd/mat/meta/operands_and_partials.hpp
./stan/math/fwd/scal/meta/operands_and_partials.hpp
./stan/math/prim/mat/meta/operands_and_partials.hpp
./stan/math/prim/scal/meta/operands_and_partials.hpp
./stan/math/rev/mat/meta/operands_and_partials.hpp
./stan/math/rev/scal/meta/operands_and_partials.hpp
```

## Some tests from the example
```
$ cd ~/scm/cmdstan/stan/lib/stan_math
$ find . -name operands_and_partials_test*
./test/unit/math/fwd/mat/meta/operands_and_partials_test.cpp
./test/unit/math/fwd/scal/meta/operands_and_partials_test.cpp
./test/unit/math/mix/mat/meta/operands_and_partials_test.cpp
./test/unit/math/prim/scal/meta/operands_and_partials_test.cpp
./test/unit/math/rev/mat/meta/operands_and_partials_test.cpp
```

## Google test
`test/unit/math/rev/mat/meta/operands_and_partials_test.cpp`
```{c, eval=FALSE, echo=TRUE}
TEST(AgradPartialsVari, OperandsAndPartialsVec) {
  ...
  vector_d d_vec(4);
  operands_and_partials<vector_d> o3(d_vec);
  EXPECT_EQ(6, sizeof(o3));
  ...
  EXPECT_FLOAT_EQ(10.0, v.val());
  EXPECT_FLOAT_EQ(10.0, grad[0]);
}

```

## Add, commit, push
```
$ git add stan/math/gpu/matrix_gpu.hpp
$ git commit -m "Informative message..."
$ git push sean descriptive-branch-name
```

## PR step 1
```{r, out.width = "100%"}
knitr::include_graphics("img/PR1.png")
```

## PR step 2
```{r, out.width = "100%"}
knitr::include_graphics("img/PR2.png")
```

## PR step 3
```{r, out.width = "100%"}
knitr::include_graphics("img/PR3.png")
```

## Stan release process
1. *Pull requests* ask for code to be added to the `develop` branch
    - `develop` is maintained in a releasable state at all times
1. Choose a point in time along the `develop` branch and *tag it with version number*
    - semantic versioning:  Major.Minor.Patch
    - only *major* changes *break backward compatibility*
    - *minor* numbers indicate new functionality
    - *patch* incremented for bugfix-only releases
1. We then *merge that tag* into the `master` branch
    - makes sure `master` is always stable
    - and always pointing at latest release
1. Additional processes used for hotfix patch releases


# Part IV: Examples

## Coding a distribution in Stan

- Use the Stan language to code the normal log pdf
    - use `_lpdf` suffix to enable sampling notation
- Place in file `my-normal.stan`    

```stan
functions {
  real my_normal_lpdf(real y, real mu, real sigma) {
    return - 0.5 * log(2 * pi())          // params: { }
           - 2 * log(sigma)               // params: { sigma }
           - 0.5 * ((y - mu) / sigma)^2;  // params: { y, mu, sigma }
  }
}
parameters { 
  real y;
}
model {
  y ~ my_normal(1.5, 3.2);
}
```

## What's missing?

- Input validation!

- Implement in Stan with the `reject` function

```stan
if (sigma < 0 || is_nan(sigma) || is_inf(sigma))
  reject("sigma must be finite, positive, found sigma = ", sigma);

if (is_nan(y) || is_inf(y))
  reject("y must be finite, found y = ", y);

if (is_nan(mu) || is_inf(mu))
  reject("mu must be finite, found mu = ", mu);
```

## Restrictions on Stan functions

* Not polymorphic---they work for a single signature
    - can't duplicate library function vectorization
    - overloading is coming, but will require multiple definitions
    
* No traits branching
    - can't skip constant terms determined by type analysis
    

## Loading RStan and compiling

```{r cache = TRUE}
library(rstan)
model <- stan_model("my-normal.stan")
```

## Fit the model

```{r cache = TRUE}
fit <- sampling(model)
```

## Summarize the posterior

* recall the posterior density is $\mathsf{Normal}(y \mid 1.5, 3.2)$
    - 3.2 is scale/std-dev, not variance or precision
    
```{r cache = TRUE}
print(fit)
```

## Coding the distribution in C++

- Like Stan, but with explicit templates and references
- Template `y` & assume `mu` and `sigma` are `double`
    - `int` promoted to `double` in C++ and to `real` in Stan
- Name resolution
    - `log(double)` found through `using std::log`
    - `log(var)`  through *argument dependent lookup*

```c++
template <typename T>
double my_normal(const T& y, double mu, double sigma) {
  using std::log;  // allow std::log as candidate for log(sigma)
  return - 0.5 * log(2 * pi())
    - 2 * log(sigma)
    - 0.5 * ((y - mu) / sigma)^2;
}
```

## Includes and main

* Need some includes:
```c++
#include <stan/math/rev/mat.hpp>    // Stan math with gradients
#include <iostream>                 // C++ I/O
```

* The `main()` provides a runnable example
```c++
int main() {
  stan::math::var y = 1.2;  // independent var
  double mu = 0.3;          // constants
  double sigma = 0.5;
  stan::math::var lp        // dependent var
    = my_normal(y, mu, sigma);
  lp.grad();                // propagate derivatives
  std::cout << "val = " << lp.val()
            << "; d.val/d.y = " << y.adj() << std::endl;
}
```

## Reverse-mode autodiff: forward pass

* Build up (directed acyclic) expression graph in forward pass
    - each node is an expression with arrows to operands
    - autodiff variable `stan::math::var` for each $v_n$
    - arena-based node memory collected after gradients

<center style="margin:1em 0 0 0">
<img src="img/agrad-expression-graph.pdf" width = 350/>
</center>

## Reverse-mode autodiff: reverse pass

*  Calculates adjoint for each node in reverse pass
    - adjoint is derivative of result w.r.t. expression
    - start with result adjoint = 1 (because $\frac{\mathrm{d}}{\mathrm{d}y}y = 1$)
    - for each node in topological order from root
```c++
adjoint[operand] += adjoint[result] * partial_result_wrt_operand;
```
*  Gradient is sequence of adjoints of inputs (independent vars)

* Time and space complexity both linear in graph size
    - times the cost of partial derivatives of each operation
    - which is usually constant in number of operands

* Slowness stems from interpretation (virtual calls)


## Custom derivative implementation

* Each `var` points to `vari`;  *roughly*:

```c++
struct var {
  vari* vi_;  // pointer to impl
};
```

* Each `vari` holds a value, adjoint, and implements a `chain()` method to propagate derivatives; *roughly*:

```c++
struct vari {
  double val_;  // values
  double adj_;  // adjoints
  vari(double val, double adj = 0) : val_(val), adj_(adj) { }
  virtual void chain() { }  // propagate derivs
};
```

## Simple Example of vari

* $\frac{\partial}{\partial a} (a \times b) = b \ \ \ \ \ \ \frac{\partial}{\partial b} (a \times b) = a$

```c++
struct multiply_vari : public vari {
  vari* op1_, op2_;
  multiply_vari(vari* op1, vari* op2)
    : vari(op1.val_ * op2.val_), op1_(op1), op2_(op2) { };

  void chain() {
    // operand adjoint += partial w.r.t. operand * result adjoint
    op1_->adj_ += op2_->val_ * this->adj_;
    op2_->adj_ += op1_->val_ * this->adj_;
  }
}
```
```c++
var operator*(const var& a, const var& b) {
  return var(new vari*(a.vi_, b.vi_));
}
```    

## Now lets do the normal distribution

* Need $\frac{\partial}{\partial y} \mathsf{Normal}(y \mid \mu, \sigma)$
* [Wolfram Alpha](http://wolframalpha.com) is way less error prone at derivatives than me
 
<center style="margin:1em 0 0 0">
<img src="img/wolfram-alpha-deriv.png" width = 500/>
</center>

## Normal vari for first argument

```c
struct my_normal_vari : public vari {
  vari* y_;  double mu_, sigma_; 
  my_normal_vari(vari* y, double mu, double sigma)
    : vari(my_normal(y.val_, mu, sigma)),  // double only
      y_(y), mu_(mu), sigma_(sigma) { }
  void chain() {
      
  }
};
```






