---
title: "Stan C++ Development:<br /> Adding a New Function"
author: "Bob Carpenter & Sean Talts"
date: "August 2018 (StanCon Helsinki)"
output:
  ioslides_presentation:
    css: styles.css
widescreen: yes
---

```{r setup, include = FALSE, warning = FALSE, cache = TRUE, echo = FALSE, comment = ""}
```

```{r echo = FALSE, include = FALSE}
library(knitr)
library(ggplot2)
```

<style>
li {
  font-family: verdana, lucida sans unicode;
  font-size: 22px;
  line-height: 1.4em;
}
pre {
  font-family: lucida console, monaco, menlo;
  font-size: 19px;
  line-height: 1.5em;
  font-weight: 500;
}
tt {
  font-family: monaco; lucida console;
  font-size: 22px;
}
code {
  font-family: monaco; lucida console;
  font-size: 22px;
}
</style>



## Documentation

* `stan-dev/stan`: [Developer process overview](https://github.com/stan-dev/stan/wiki/Developer-process-overview)

* `stan-dev/stan`: [Contributing new functions to Stan](https://github.com/stan-dev/stan/wiki/Contributing-New-Functions-to-Stan)

* `stan-dev/math`: [Adding a new function with known gradients](https://github.com/stan-dev/math/wiki/Adding-a-new-function-with-known-gradients)

* `stan-dev/math`: [Developer doc](https://github.com/stan-dev/math/wiki/Developer-Doc)



## Best and Worst Decisions for Stan?
* What are the best and worst decisions you made regarding the implementation of Stan?
    - *Worst decision*: using C++
    - *Best decision*: using C++


## Why C++?
* It's **not the easiest language** in the world
    - the spec is incomplete by design so *compilers vary*, even by optimization
    - it's been a *moving target* from C++03 to C++20
    - low-level memory access and pointers makes it *dangerous*
* But it's **very powerful**
    - whole *new language with C++11* and beyond
    - decent *matrix and math libs* (like Fortran, unlike all else)
    - *control memory* for autodiff
    - *template overloads* for autodiff
    - *static evaluation* of branchpoints (template metaprograms are why C++ is fast)
    - *elimination of intermediates* (via expression templates)
    - *native in-memory communication* with Python and R

    
## Overall Stan Organization
* Stan transpiler converts Stan program to C++ class for model
    - standard parser, abstract syntax tree, generator design
* C++ class includes the Stan math library
* C++ class compiled mostly header only along with algorithms and math library
* Result is executable (CmdStan) or dynamically linked object code (RStan, PyStan)

## Stan language is translated to a C++ model
* Creates a C++ model class with a known interface
* Model class is constructed with the data you pass in when you go to fit the model
* Primary entry point on the class is the `log_prob` function
    - Takes in parameter values and returns their log probability density (potentially up to a constant)


## The Stan to C++ translator
* Called many things - compiler, transpiler, parser
* Also written in C++
* Lives in the Stan repo alongside the algorithms and services (`lang`)
* Functions are first defined in the Math library and then exposed in the Stan language


## C++ Model Compiled to Object Code
* Includes the Math library - most or all functions and data types are defined there
* Compiled with the Stan algoirthms
* Some basic functionality for I/O lives in CmdStan, which presents the interface a user sees on the command line


## Current Repository Structure
* Repositories `cmdstan`, `pystan`, `rstan` include `stan`; `stan` includes  `math`
    - Git submodules
* CmdStan has the Stan repo as a git submodule at `stan/`
* Stan has the Math library as a git submodule at `lib/stan_math` 
    - `stan/lib/stan_math` to CmdStan
* Math library directly includes Boost, Eigen, Sundials at `lib/`
    - `stan/lib/stan_math/lib` to CmdStan


## A Stan Program
* `Matrix program(Matrix data) {...}`
    - Function from data to a sample of parameter draws typical given that data and model
* Compiled with a few algorithms that use the model density to find typical parameter draws
* Most of the complexity lies in the likelihood and is built using functions in the Math library


## Most of Stan's code is in the Math library
* Provides users with many functions to express complicated likelihoods
* Autodiff system gives the algorithms the gradients they need automatically for any Stan or Math library code
* Split up into `stan` and `test`
* Then split by autodiff mode: `prim`, `rev`, `fwd`, `mix`
* Then further split by container type: `scal`, `arr`, `mat` (this is going away)
* Sometimes further split up by functionality: `err`, `fun`, `meta`, `prob`, ...

## Tests and continuous integration
* We use [googletest](https://github.com/google/googletest), a C++ testing framework for unit tests
    - tests end in `_test.cpp`
    - provides macros like `TEST(SuiteName, TestName)` and `EXPECT_EQ(actual, expected)`
* Test directory structure parallel to `src` stucture
* Run tests locally with `runTests.py` helper script on a directory or test
* Jenkins at http://d1m1s1b1.stat.columbia.edu:8080/
    - Specified in code, in a top-level file named `Jenkinsfile`
* [This wiki](https://github.com/stan-dev/stan/wiki/Supported-C---Compilers-and-Language-Features) tries to collate which OSes and toolchains are tested

## Developer process
0. For larger changes only: Discourse discussion and/or design review
1. Github issue describing the problem 
2. Add a description of the proposed technical solution to the github issue
3. Create a GitHub pull request
4. [Code Review](https://github.com/stan-dev/math/wiki/Developer-Doc#code-review-guidelines)
5. Merge

## Setting up GitHub
* Create an account
* (optional) [Set up SSH keys](https://help.github.com/articles/connecting-to-github-with-ssh/)
* Fork repo(s) from stan-dev
* `git clone --recursive <cmdstan repo>`
* Add your fork as a remote on the repo you care about

## Clone CmdStan
```{r, out.width = "100%"}
knitr::include_graphics("img/clone cmdstan.png")
```

## Fork Math repo
```{r, out.width = "100%"}
knitr::include_graphics("img/fork.png")
```


## My fork 
![](img/my fork.png)

## Set up fork as remote in local clone of CmdStan
```
$ git remote -v
origin	git@github.com:stan-dev/math.git (fetch)
origin	git@github.com:stan-dev/math.git (push)
$ git remote add sean git@github.com:seantalts/math.git
$ git remote -v
origin	git@github.com:stan-dev/math.git (fetch)
origin	git@github.com:stan-dev/math.git (push)
sean	git@github.com:seantalts/math.git (fetch)
sean	git@github.com:seantalts/math.git (push)
```

## Creating a PR
Fairly standard open source flow:

1. (optional) create a branch
1. write code, tests, and doc
1. run appropriate checks - cpplint, appropriate unit tests, (optional) `clang-format`
1. add files
1. commit with a [message about what you were trying to accomplish](https://chris.beams.io/posts/git-commit/) 
1. `git push origin <branchname>`
1. open PR on appropriate `stan-dev` repo

## Creating a branch
```
$ git checkout -b descriptive-branch-name
Switched to a new branch 'descriptive-branch-name'
```

## Running the checks
1. `python runTests.py -j{num_cores} path/to/test.cpp /path/to/test/dir`
1. `make cpplint`
1. (optional) [Auto-formatting - git hook, editor plugin](https://github.com/stan-dev/stan/wiki/Coding-Style-and-Idioms#clang-format)

## A complicated example
```
$ cd <math clone>
$ find . -name operands_and_partials.hpp

./stan/math/fwd/mat/meta/operands_and_partials.hpp
./stan/math/fwd/scal/meta/operands_and_partials.hpp
./stan/math/prim/mat/meta/operands_and_partials.hpp
./stan/math/prim/scal/meta/operands_and_partials.hpp
./stan/math/rev/mat/meta/operands_and_partials.hpp
./stan/math/rev/scal/meta/operands_and_partials.hpp
```

## Some tests from the example
```
$ cd ~/scm/cmdstan/stan/lib/stan_math
$ find . -name operands_and_partials_test*
./test/unit/math/fwd/mat/meta/operands_and_partials_test.cpp
./test/unit/math/fwd/scal/meta/operands_and_partials_test.cpp
./test/unit/math/mix/mat/meta/operands_and_partials_test.cpp
./test/unit/math/prim/scal/meta/operands_and_partials_test.cpp
./test/unit/math/rev/mat/meta/operands_and_partials_test.cpp
```

## Google test
`test/unit/math/rev/mat/meta/operands_and_partials_test.cpp`
```{c, eval=FALSE, echo=TRUE}
TEST(AgradPartialsVari, OperandsAndPartialsVec) {
  ...
  vector_d d_vec(4);
  operands_and_partials<vector_d> o3(d_vec);
  EXPECT_EQ(6, sizeof(o3));
  ...
  EXPECT_FLOAT_EQ(10.0, v.val());
  EXPECT_FLOAT_EQ(10.0, grad[0]);
}

```

## Add, commit, push
```
$ git add stan/math/gpu/matrix_gpu.hpp
$ git commit -m "Informative message..."
$ git push sean descriptive-branch-name
```

## PR step 1
```{r, out.width = "100%"}
knitr::include_graphics("img/PR1.png")
```

## PR step 2
```{r, out.width = "100%"}
knitr::include_graphics("img/PR2.png")
```

## PR step 3
```{r, out.width = "100%"}
knitr::include_graphics("img/PR3.png")
```

## Stan release process
1. Pull requests ask for code to be added to the `develop` branch
1. When creating a release, we choose a point in time along the `develop` branch and tag it as a certain release
1. We then merge that tag into the `master` branch, such that `master` is always stable
1. (Additional process for hotfixes to already-released code)








## Coding a distribution in Stan

- Use the Stan language to code the normal log pdf
    - use `_lpdf` suffix to enable sampling notation
- Place in file `my-normal.stan`    

```stan
functions {
  real my_normal_lpdf(real y, real mu, real sigma) {
    return - 0.5 * log(2 * pi())          // params: { }
           - 2 * log(sigma)               // params: { sigma }
           - 0.5 * ((y - mu) / sigma)^2;  // params: { y, mu, sigma }
  }
}
parameters { 
  real y;
}
model {
  y ~ my_normal(0, 3.2);
}
```

## What's missing?

- Input validation!

- Implement in Stan with the `reject` function

```stan
if (sigma < 0 || is_nan(sigma) || is_inf(sigma))
  reject("sigma must be finite, positive, found sigma = ", sigma);

if (is_nan(y) || is_inf(y))
  reject("y must be finite, found y = ", y);

if (is_nan(mu) || is_inf(mu))
  reject("mu must be finite, found mu = ", mu);
```

## Restrictions on Stan functions

* Not polymorphic---they work for a single signature
    - can't duplicate library function vectorization
    - overloading is coming, but will require multiple definitions
    
* No traits branching
    - can't skip constant terms determined by type analysis
    

## Loading RStan and compiling

```{r cache = TRUE}
library(rstan)
model <- stan_model("my-normal.stan")
```

## Fit the model

```{r cache = TRUE}
fit <- sampling(model)
```

## Summarize the posterior
```{r cache = TRUE}
print(fit)
```

## Coding the distribution in C++

- Like Stan, but with explicit templates and references
- Template `y` & assume `mu` and `sigma` are `double`
    - `int` promoted to `double` in C++ and to `real` in Stan
- Name resolution
    - `log(double)` found through `using std::log`
    - `log(var)`  through *argument dependent lookup*

```c++
template <typename T>
double my_normal(const T& y, double mu, double sigma) {
  using std::log;  // allow std::log as candidate for log(sigma)
  return - 0.5 * log(2 * pi())
    - 2 * log(sigma)
    - 0.5 * ((y - mu) / sigma)^2;
}
```

## Includes and main

* Need some includes:
```c++
#include <stan/math/rev/mat.hpp>    // Stan math with gradients
#include <iostream>                 // C++ I/O
```

* The `main()` provides a runnable example
```c++
int main() {
  stan::math::var y = 1.2;  // independent var
  double mu = 0.3;          // constants
  double sigma = 0.5;
  stan::math::var lp        // dependent var
    = my_normal(y, mu, sigma);
  lp.grad();                // propagate derivatives
  std::cout << "val = " << lp.val()
            << "; d.val/d.y = " << y.adj() << std::endl;
}
```

## Reverse-mode autodiff: forward pass

* Build up (directed acyclic) expression graph in forward pass
    - each node is an expression with arrows to operands
    - autodiff variable `stan::math::var` for each $v_n$
    - arena-based node memory collected after gradients

<center style="margin:1em 0 0 0">
<img src="img/agrad-expression-graph.pdf" width = 350/>
</center>

## Reverse-mode autodiff: reverse pass

*  Calculates adjoint for each node in reverse pass
    - adjoint is derivative of result w.r.t. expression
    - start with result adjoint = 1 (because $\frac{\mathrm{d}}{\mathrm{d}y}y = 1$)
    - for each node in topological order from root
```c++
adjoint[operand] += adjoint[result] * partial_result_wrt_operand;
```
*  Gradient is sequence of adjoints of inputs (independent vars)

* Time and space complexity both linear in graph size
    - times the cost of partial derivatives of each operation
    - which is usually constant in number of operands

* Slowness stems from interpretation (virtual calls)


## Custom derivative implementation

* Each `var` points to `vari`;  *roughly*:

```c++
struct var {
  vari* vi_;  // pointer to impl
};
```

* Each `vari` holds a value, adjoint, and implements a `chain()` method to propagate derivatives; *roughly*:

```c++
struct vari {
  double val_;  // values
  double adj_;  // adjoints
  vari(double val, double adj = 0) : val_(val), adj_(adj) { }
  virtual void chain() { }  // propagate derivs
};
```

## Simple Example of vari

* $\frac{\partial}{\partial a} (a \times b) = b \ \ \ \ \ \ \frac{\partial}{\partial b} (a \times b) = a$

```c++
struct multiply_vari : public vari {
  vari* op1_, op2_;
  multiply_vari(vari* op1, vari* op2)
    : vari(op1.val_ * op2.val_), op1_(op1), op2_(op2) { };

  void chain() {
    // operand adjoint += partial w.r.t. operand * result adjoint
    op1_->adj_ += op2_->val_ * this->adj_;
    op2_->adj_ += op1_->val_ * this->adj_;
  }
}
```
```c++
var operator*(const var& a, const var& b) {
  return var(new vari*(a.vi_, b.vi_));
}
```    

## Now lets do the normal distribution

* Need $\frac{\partial}{\partial y} \mathsf{Normal}(y \mid \mu, \sigma)$
* [Wolfram Alpha](http://wolframalpha.com) is way less error prone at derivatives than me
 
<center style="margin:1em 0 0 0">
<img src="img/wolfram-alpha-deriv.png" width = 500/>
</center>

## Normal vari for first argument

```c
struct my_normal_vari : public vari {
  vari* y_;  double mu_, sigma_; 
  my_normal_vari(vari* y, double mu, double sigma)
    : vari(my_normal(y.val_, mu, sigma)),  // double only
      y_(y), mu_(mu), sigma_(sigma) { }
  void chain() {
      
  }
};
```






